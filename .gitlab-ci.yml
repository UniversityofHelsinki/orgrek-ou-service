image: frolvlad/alpine-glibc

before_script:
  - apk update && apk --no-cache add g++ gcc libgcc libstdc++ linux-headers make python3 curl tar
  - apk --no-cache add openjdk11 --repository=http://dl-cdn.alpinelinux.org/alpine/edge/community
  - apk add maven

cache:
  paths:
    - .m2/repository/

# Define the stages
stages:
  - test
  - build
  - audit_scan
  - deploy

# Define the process for each stage

test :
  stage: test
  tags:
    - ohtu-build-1
  script:
    - mvn test
    - cat target/site/jacoco/index.html | grep -o 'Total[^%]*%'
  coverage: "/Total.*?([0-9]{1,3})%/"
  artifacts:
    paths:
      - target/site/jacoco/jacoco.xml
    expire_in: 1 mos


build :
  stage: build
  tags:
    - ohtu-build-1
  script:
    - java -version
    - mvn install
  artifacts:
    name: orgrek-ous-build-$CI_BUILD_ID-$CI_BUILD_REF
    paths:
      - target/*.jar


  # Define the process for deploy stage to development environment
deploy_dev:
  stage: deploy
  tags:
    - ohtu-build-1
  environment:
    name: development
  only:
    - main
  except:
    - schedules
  script:
    - curl -fsSLO --compressed "https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux.tar.gz";
    - tar xvzf openshift-client-linux.tar.gz -C /usr/local/bin
    # before any action, I connect to the OpenShift server with the appropriate credentials
    - oc login https://$OPENSHIFT_ADDR_TEST:$OPENSHIFT_PORT --token=$OPENSHIFT_TOKEN_TEST
    - oc project organisaatiorekisteri
    # list environment variables here
    - oc set env dc/organisaatiorekisteri-ou-service-dev URL=$DB_POD_URL_DEV
    - oc set env dc/organisaatiorekisteri-ou-service-dev PORT=$OU_SERVICE_PORT
    # start build process
    - oc start-build organisaatiorekisteri-ou-service-dev --from-dir=. --follow
    # patch build config
    - oc patch bc/organisaatiorekisteri-ou-service-dev --patch '{"spec":{"successfulBuildsHistoryLimit":1}}'
    - oc patch bc/organisaatiorekisteri-ou-service-dev --patch '{"spec":{"failedBuildsHistoryLimit":1}}'

deploy_test:
  stage: deploy
  tags:
    - ohtu-build-1
  environment:
    name: test
  only:
    - test
  script:
    - curl -fsSLO --compressed "https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux.tar.gz";
    - tar xvzf openshift-client-linux.tar.gz -C /usr/local/bin
    # before any action, I connect to the OpenShift server with the appropriate credentials
    - oc login https://$OPENSHIFT_ADDR_TEST:$OPENSHIFT_PORT --token=$OPENSHIFT_TOKEN_TEST
    - oc project organisaatiorekisteri
    # list environment variables here
    - oc set env dc/organisaatiorekisteri-ou-service-test URL=$DB_POD_URL_TEST
    - oc set env dc/organisaatiorekisteri-ou-service-test PORT=$OU_SERVICE_PORT
    # start build process
    - oc start-build organisaatiorekisteri-ou-service-test --from-dir=. --follow
    # patch build config
    - oc patch bc/organisaatiorekisteri-ou-service-test --patch '{"spec":{"successfulBuildsHistoryLimit":1}}'
    - oc patch bc/organisaatiorekisteri-ou-service-test --patch '{"spec":{"failedBuildsHistoryLimit":1}}'

deploy_prod:
  stage: deploy
  tags:
    - ohtu-build-1
  environment:
    name: prod
  only:
    - prod
  when: manual
  script:
    - curl -fsSLO --compressed "https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux.tar.gz";
    - tar xvzf openshift-client-linux.tar.gz -C /usr/local/bin
    # before any action, I connect to the OpenShift server with the appropriate credentials
    - oc login https://$OPENSHIFT_ADDR_PROD:$OPENSHIFT_PORT --token=$OPENSHIFT_TOKEN_PROD
    - oc project organisaatiorekisteri
    # list environment variables here
    - oc set env dc/organisaatiorekisteri-ou-service-prod URL=$DB_POD_URL_PROD
    - oc set env dc/organisaatiorekisteri-ou-service-prod PORT=$OU_SERVICE_PORT
    # start build process
    - oc start-build organisaatiorekisteri-ou-service-prod --from-dir=. --follow
    # patch build config
    - oc patch bc/organisaatiorekisteri-ou-service-prod --patch '{"spec":{"successfulBuildsHistoryLimit":1}}'
    - oc patch bc/organisaatiorekisteri-ou-service-prod --patch '{"spec":{"failedBuildsHistoryLimit":1}}'

# Rules for the scheduled npm audit and outdated scans
dependency scanning:
  stage: audit_scan
  tags:
    - ohtu-build-1
  allow_failure: true
  only:
    - schedules
  script:
    # Run OWASP audit and write outputs to a txt file.
    - echo "=== Running OWASP diagnostics ==="
    - export RESULT_FILE="./target/dependency-check-report.html"
    - mvn clean install -Powasp-dependency-check
    - echo "Done with OWASP diagnostics."
    - echo "Sending results to Slack..."
    # Send result file to "audit-logs" channel in Ohtu's Slack space (see https://api.slack.com/methods/files.upload).
    - "curl -F file=@${CI_PROJECT_DIR}/$RESULT_FILE -F 'initial_comment=Orgrek-ou-service audit scan report' -F channels=${AUDIT_RESULT_SLACK_CHANNEL_ID} -F filename=$RESULT_FILE -F filetype=text -H 'Authorization: Bearer '${SLACK_FILE_UPLOAD_TOKEN} https://slack.com/api/files.upload"
    - echo "Done with sending results to Slack."
    - export RESULT_NEW_VERSIONS_FILE="./new-versions.txt"
    - echo " === Scanning maven dependencies with newer versions ===" >> $RESULT_NEW_VERSIONS_FILE
    - echo "" >> $RESULT_NEW_VERSIONS_FILE
    - mvn versions:display-dependency-updates >> $RESULT_NEW_VERSIONS_FILE
    - echo "" >> $RESULT_NEW_VERSIONS_FILE
    - echo " === Scanning maven dependencies with plugin updates ===" >> $RESULT_NEW_VERSIONS_FILE
    - echo "" >> $RESULT_NEW_VERSIONS_FILE
    - mvn versions:display-plugin-updates >> $RESULT_NEW_VERSIONS_FILE
    # Send result file to "audit-logs" channel in Ohtu's Slack space (see https://api.slack.com/methods/files.upload).
    - "curl -F file=@${CI_PROJECT_DIR}/$RESULT_NEW_VERSIONS_FILE -F 'initial_comment=Orgrek-ou-service new maven dependencies versions / plugins report' -F channels=${AUDIT_RESULT_SLACK_CHANNEL_ID} -F filename=$RESULT_NEW_VERSIONS_FILE -F filetype=text -H 'Authorization: Bearer '${SLACK_FILE_UPLOAD_TOKEN} https://slack.com/api/files.upload"
    - echo "Done with sending results to Slack."

